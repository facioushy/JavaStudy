# 简

## 计算机网络

###  tcp和udp报文段的首部格式

tcp: 源端口，目的端口；序号；确认号；**数据偏移**；留空；**标志位**

udp：源端口，目的端口；**数据包长度**；校验值

### tcp三次握手和四次挥手

三次握手：

1. 客户端发送连接请求，**SYN = 1**, seq = x;
2. 服务端收到请求，返回**SYN = 1**, seq = y，**ACK = 1, ack = x+1**;
3. 客户端再返回**ACK = 1**, **seq = x+1**, ack = y+1

四次挥手：

1. 客户端发送断开请求，FIN = 1, seq = x;
2. 服务端收到请求，返回ack = x+1, ACK = 1, seq = y;
3. 服务端发送断开请求，FIN = 1, seq = y, **ACK = 1 ack = x+1**;
4. 客户端收到断开请求，返回ack=y+1, ACK = 1, seq = y+1;

### 为什么要三次握手

如果没有进行第三次握手，此时当该请求超时时，客户端会再次发送请求，而超时的请求最终也会到达服务端，所以如果不进行第三次握手服务端和客户端之间会建立多个连接，而第三次握手会忽视掉之后到达的连接请求。

### 为什么要四次挥手

第一次：客户端要与服务器断开连接，服务端知道客户端要与自己断开连接，进行第一次挥手

第二次：服务端确认收到客户端发送的断开请求，客户端知道服务端已经收到请求，进行二次挥手

第三次：服务端已经没有需要发送给客户端的数据了，服务端发送一个断开请求，客户端知道服务端需要断开连接，进行三次挥手

第四次：客户端返回一个消息，此时服务端知道客户端已经知道客户端收到了自己的请求后不会再发送数据

### 四次挥手后等待2MSL的意义

1. 确保最后一次挥手请求能够到达客户端。如果服务端未收到客户端的确认报文，会再次发送请求断开连接报文。
2. 为了让下一次连接中不会出现旧的数据。

### TCP和UDP的区别

tcp：面向连接，可靠的，点对点的，面向字节流，**有拥塞机制，首部开销大**

udp：无连接的，不可靠的，一对一、多对多。。。面向报文，无拥塞机制，首部开销大

### UDP应用场景：

对当前网络通讯质量要求不高的时候，要求网络通讯速度尽量的快

视频会议，直播

### TCP怎么保证传输可靠

1. 校验和：发送方发送前会计算校验和，接收方收到数据后也会计算校验和，若不同则会拒绝接收
2. 发送数据的时候进行编号：seq
3. 流量控制：流量窗口，**接收方会在返回ACK时把自己的流量窗口的大小填入报文**，发送方会根据窗口的大小控制速度
4. 拥塞控制：慢开始，拥塞避免，快重传，快恢复
5. 超时重传
6. 三次握手，四次挥手

### 拥塞控制

慢开始，拥塞避免，快重传，快恢复

TCP在开始传输时，如果开始就发送大量数据，而此时网络拥塞，会更加加剧网络的拥塞，所以设置了慢开始，在刚开始发送数据的时候，先发送少量的数据(此时拥塞窗口为1)，然后经过一次传输，拥塞窗口加倍，但是也不能使拥塞窗口一直指数式增长，需要设置一个阈值，达到这个阈值之后，拥塞窗口就变为线性增长。而之后如果网络出现拥塞，发生超时重传，慢开始的阈值变为原来一半，拥塞窗口重置为1，再次重复上述步骤。

### OSI七层和TCP/IP四层

OSI七层：物理层，链路层，网络层，传输层，**会话层，表示层**，应用层

TCP/IP四层：物理链路层，网络层，传输层，应用层

**会话层**：提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制，如**服务器验证用户登录**便是由会话层完成的。在会话层封装会话控制参数。

**表示层：**主要解决用户信息的语法表示问题，如加密解密。在表示层进行代码/编码转换。

### 常见的应用层、运输层、网络层协议和硬件应该在哪一层

应用层：HTTP **SMTP FTP** DNS

传输层：TCP UDP

网络协议层：IP **ICMP 路由 防火墙**

数据链路层：**网卡，网桥，交换机**

物理层：**中继器，集线器**

### HTTP 1.0和1.1的区别

1.1设置了长连接，1.0为短连接

**新增了错误状态码**

**缓存处理**：HTTP1.1则引入了更多的缓存控制策略

**带宽优化及网络连接的使用：**HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头引入了**range头域**，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。

### HTTP2.0的变化

二进制格式：2.0协议解析采用的是二进制

首部压缩

服务器推送

**多路复用**：即连接共享，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1.1大了好几个数量级。

### HTTP和HTTPS的区别

Http是超文本传输协议，**信息明文**，HTTPS = HTTP+SSL，即进行了SSL加密，更加安全

HTTP和HTTPS使用**端口不同**

### HTTPS流程、HTTPS和对称/非对称加密

第一阶段：证书校正

1. 客户端发送连接请求
2. 客户端返回证书
3. 客户端验证证书是否合法，不合法会跳出告警

第二阶段：数据连接

1. 服务端将公钥发送给客户端
2. 客户端在收到公钥之后会在本地生成一个随机数
3. 随机数通过公钥加密，返回给服务端
4. 服务端通过私钥对随机数进行解密

对称加密：加密解密使用同一个密钥，加密解密速度快，典型算法有**DES AES？？？**

非对称加密：加密解密使用的密钥成对出现（无法根据私钥推出公钥，反之也不行），加密解密使用不同密钥（公钥加密，私钥解密，或者私钥加密，公钥解密），加密解密速度慢，典型的非对称加密算法有**RSA、DSA？？？**

### 简述HTTP请求中GET和POST的区别及数据包格式

GET：对于服务器的资源的简单请求，参数包含在URL中

POST：可以包含用户提交的数据，参数在request body中。

**GET请求，浏览器会把header和data一起发送出去，而POST请求，浏览器会先把header发送出去，等待服务端返回100 continue之后，再发送data内容**

### HTTP码

1XX：请求处理中，100 continue

2XX：请求成功，请求被处理，如200 OK

3XX：重定向，要完成请求需进一步操作。301，Moved Permanently，永久重定向

4XX：客户端错误。404，访问资源不存在

5XX：服务端错误。500，服务器发生不可预估的错误

### DNS解析过程

1. 现在浏览器缓存内寻找域名对应的IP
2. 如果没有，再在本地hosts文件中
3. 如果没有，在路由缓存内找
4. 如果没有，在DNS服务器找（本地域名、顶级域名、根据名）

### 用户在浏览器输入一个URL后的过程

1. 首先进行一次DNS解析，DNS解析首先会在浏览器的缓存内找域名对应的IP地址，没找到就在本地找，再到路由缓存找，再到本地服务器（这台服务器一般在你的城市的某个角落）内找，没有则去根域名服务器发出查询请求，根域名服务器会返回给LDNS一个所查询域的主域名服务器（gTLD Server，国际顶尖域名服务器，如.com .cn .org等）地址。DNS服务器是基于UDP的。
2. 得到IP地址之后，客户端会给服务端发送一个HTTP连接请求。GET
3. 到传输层，使用TCP协议，对HTTP进行封装，**加入了端口号**
4. 到网络层，使用IP协议对IP地址封装成IP数据报，之后用到了ARP协议，会把包含IP地址的ARP请求广播到网络上的所有主机，接收到返回的消息得到对方主机的MAC地址
5. 链路层，对IP数据包增加首部和尾部之后封装成MAC帧。根据目的MAC开始建立TCP连接。服务端接收到MAC帧之后，识别帧的首部和尾部，然后将中间的数据返回到网络层，然后逐层返回到应用层
6. 服务端响应请求，返回资源给客户端
7. 断开TCP连接，浏览器对界面进行渲染呈现给客户端

### SELECT EPOLL POLL

SELECT：每个客户端的套接字会存放在一个集合中，而SELECT对这个集合进行监听，如果集合中有套接字可读，便可去读取资源。时间复杂度O（n）

POLL：poll和select类似，但是底层所使用的集合不同，可存放任意数量的连接。时间复杂度O（n)

EPOLL：epoll是**事件驱动**的，哪个流发生了事件会通知我们，所以事件复杂度是O（1）

### BIO NIO AIO

BIO: 同步阻塞IO， 一个连接一个线程。

NIO: 同步非阻塞IO，**基于Reactor模型**，客户端和channel进行通信，服务端通过selector来轮询channel，之后再进行IO操作。一个请求一个线程

AIO: 异步非阻塞IO，IO读写请求完成之后操作系统会通知你，一个有效请求一个线程。

### 如何理解同步和阻塞

IO操作包含两部分：

1. 发起IO请求
2. 进行IO操作

阻塞与非阻塞在于1， NIO通过channel发出IO请求之后，就返回了，所以是非阻塞，

同步和异步在于2， AIO是系统已经完成了IO操作之后再通知，而NIO是系统通知该去完成IO操作了

### 谈一谈对Reactor的理解

Reactor模型包含两个部分：

1. Reactor：负责查询、响应IO事件
2. Handler：用于处理IO事件

单线程Reactor：reactor和handler在一个线程中，一个handler阻塞，其他所有handler无法执行

单Reactor多线程：单个reactor承担了所有的事件监听、响应工作，如果连接过多，还是可能存在性能问题。

多Reactor多线程：其中mainReactor建立连接，多个subReactor则负责数据读写。

### HTTP报文格式

请求报文

第一行：请求方法 URL 协议版本

第二行及之后：首部Header

头部和body部分用一个空格隔开

请求主体

响应报文：

第一行：协议版本、状态码

之后：首部内容

空格分离

响应内容主体

### Header的关键词

请求：

Cookie: 每次发请求，都会带到服务端

Accept-Encoding: 浏览器支持的格式

响应：

Content-Type：设置响应内容的类型和编码, 经常配合mime模块使用

Aged：推算资源创建经过时间

### XSS跨脚本攻击 如何避免

用户在网页中插入自己的脚本，让其在用户访问网页时在其浏览器中进行执行，如cookie来发送到攻击者自己的网站

如何避免：

**对输入(和URL参数)进行过滤，对输出进行编码**。

+ 将容易导致XSS攻击的**边角字符替换成全角字符**
+ 对所有要动态输出到页面的内容，通通**进行相关的编码和转义**。
+ XSS 一般利用js脚步读取用户浏览器中的Cookie，而如果在服务器端对 **Cookie 设置了HttpOnly 属性**，那么js脚本就不能读取到cookie，但是浏览器还是能够正常使用cookie。

### Cookie和Session聊一下

Session在服务端，Cookie在客户端

Session依赖SessionID， 而SessionID在Cookie中，如果Cookie被禁用需要其他方法实现SessionID

Cookie不安全

### Session实现原理

1. 第一次访问服务器时创建session对象，同时给session对象分配一个sessionID
2. 服务端会把SeesionID返回给浏览器的Cookie中保存
3. 之后访问时，浏览器会把带有SessionID的Cookie发送到服务端
4. 服务器得到SessionID之后，在内存中搜索相对应的编号的session对象
5. 有则返回，找不到返回null，然后继续回到第一步重复

### 没有Cookie能使用Session码

可以，把SessionID放到url中一起发送

### 多台服务器共享Session

1. memcache同步session
2. redis共享session
3. mysql共享session
4. cookie共享session
5. 服务器之间数据同步

### TCP粘包现象原因和解决方法

发送方原因：算法的问题，发送方需要在对方返回确认接收之后才会发送下一个包，而此时会有好多个包堆在一个造成粘包的现象

接收方原因：TCP接收到数据并没有马上返回到应用层，而是存放在缓存中，需要应用程序主动去缓存读取，所以如果接收到数据的速率大于读取的速率就回造成粘包

解决方法：

1. **包头加上包体长度**
2. 加上\r\n标记
3. **定长发送**

## Mysql

### ACID，Mysql如何保证实现的

A:  原子性，一个事务要么全部成功，要么全部失败。比如有两个账号，A和B，A转B100元，这里面有两个动作A-100， B+100，这两个动作不可分割即原子性。

C**:  一致性**，从一个一致性的状态转到另一个一致性的状态。A和B两者的钱加起来是5000，不管A和B之间如何转账，事务结束后两个用户的钱加起来应该还是5000.

I： 隔离性，一个事务在提交之前，他的修改对其他事务都是不可见的

D：持久性，事务提交之后，他对数据库的修改是持久的，即使数据库发生了故障也不会变化

实现保证：

原子性：undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。

一致性：通过undo，回滚机制来保证

隔离性：通过给操作的对象加悲观锁或者乐观锁，MVCC(undo log)来保证

持久性：是通过redo来保证的。

### 索引数据的选择

1. hash表：1.所有数据都要进入内存，耗费内存 2.等值查询很快，但实际环境范围查询更多，hash不合适

2. 二叉树：容易不平衡，极端情况下退化成链表，查询效率低 

3. AVL：查询效率提升，代价：插入效率慢，左旋右悬 

4. 红黑树：最长子树不超过最短子树的两倍。牺牲一些查询效率换插入效率

5. B树：二叉树随着插入节点加深，深度变大，每一层一次IO，太频繁——>内存和磁盘以页为基本交换单位。B树，多路查找树，一页一个node。减少IO

6. B+树：每个节点里data占了空间——>每个节点只存放key，data都放到叶节点，减小树深，进一步减小IO。代价：增加了一些key的数据冗余

   2.叶结点data双向指针链接，适合范围查询、升序降序

#### b+树为什么一般3-4行

B+树存放总记录数为：根节点数指针数*单个叶子节点记录行数。单个叶子节点记录数=16K/1K（一般记录的大小为1K），主键ID为bigint类型，长度为8字节，指针为6字节，一共14字节，那一个页为16K 即，16384字节/14字节=1170。高度为2的话能存放1170 X 16 = 18720， 高度为3的话1170 X 1170 X 16 = 21902400。在查找数据时一次页的查找代表一次IO 

### 乐观锁和悲观锁是什么，InnoDB的标准行级锁有哪两种

乐观锁：对数据进行操作的时候认为没有其他线程对其进行访问。不使用数据库锁和阻塞线程的方法。一般是在需要锁的数据上增加一个版本号，或者时间戳。

悲观锁：对数据进行操作的时候认位一定会有其他线程对其进行访问，所以在整个处理过程中会对数据进行锁定状态。**通常通过常用的select … for update操作来实现悲观锁**，在SQL的最后加入for update语句，就可以在数据库事务执行过程中，锁定查询出来的数据，其他事务将不能再对其进行读写操作，这样避免了数据的不一致，单个请求直至数据库事务完成，才会释放这个锁。

标准锁：

读锁：共享锁 S锁，事务读取一行数据的时候，允许多个数据同时获取

写锁：排他锁 X锁，允许事务删除或更新一行数据。

表级锁：

意向共享锁（IS锁）：事务想要获得一张表中某几行的共享锁，事务再给一个数据行加共享锁之前必须先取得该表的IS锁。

意向排他锁（IX锁）：事务想要获得一张表中某几行的排他锁，事务在给一个数据行加排他锁之前必须先取得该表的IX锁。

### 数据库的隔离级别有哪些，含义，Mysql的默认级别是什么

1. 未提交读——脏读、幻读和不可重复读
2. 已提交读——幻读和不可重复读
3. 可重复度（默认）——幻读
4. 串行化：他会给每一行读取的数据加锁，会导致大量超时和锁竞争的问题。

### 丢失修改、脏读、不可重复读、幻读

丢失修改：T1和T2对一个数据进行修改，T1先改，T2后改，T2的修改覆盖了T1的

脏读：T1修改一个数据但未提交，T2读取这个数据，但此时T1回滚了这次修改，那么T2的读取数据是脏数据

不可重复读：T2读取一个数据，T1修改了这个数据，T2再读这个数据与第一次读取的结果不同

幻读：T1读取某个范围的数据，T2在这个范围内插入新的数据，T1再次读取这个范围内的数据，结果不同

在默认的事务隔离级别下，InnoDB存储引擎采用**Next-Key Locking**机制来避免幻读。

不可重复读的重点是修改，幻读的重点在于新增或者删除。

例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。

例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。

### 隔离级别的单位是数据表还是数据行，如串行化级别，两个事务访问不同的数据行，能并发吗

读未提交：不加锁

读已提交：加行锁，只锁要修改的行

可重复读：加行锁，锁定的是查询的行

可串行化：加表锁，在读取的每张表上加锁

### Mysql的行级锁有哪些

record lock：锁定单个行的锁

gap lock：锁定一个范围内的锁，不包括当前记录

next-key lock：锁定一个范围包括记录本身

### Mysql有哪些存储引擎，优缺点

MyISAM:支持表锁，适合读密集的场景，不支持外键，不支持事务，索引与数据在不同的文件

InnoDB：支持行、表锁，默认为行锁，适合并发场景，支持外键，支持事务，索引与数据同一文件

外键：设表t1,t2中都有一个name字段,而且是t1的主键，那么如果设t2中的name为外键的话，向t2中添加数据的时候,如果name值不在t1之中就会报错。

阿里巴巴开发手册这样说到：

> 【强制】不得使用外键与级联，一切外键概念必须在应用层解决。

为什么不要用外键呢？

> 1. **增加了复杂性：** a.每次做DELETE 或者UPDATE都必须考虑外键约束，会导致开发的时候很痛苦,测试数据极为不方便;b.外键的主从关系是定的，假如那天需求有变化，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦。
> 2. **增加了额外工作**： 数据库需要增加维护外键的工作，比如当我们做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，保证数据的的一致性和正确性，这样会不得不消耗资源；（个人觉得这个不是不用外键的原因，因为即使你不使用外键，你在应用层面也还是要保证的。所以，我觉得这个影响可以忽略不计。）
> 3. 外键还会因为需要请求对其他表内部加锁而容易出现死锁情况；
> 4. **对分库分表不友好** ：因为分库分表下外键是无法生效的。
> 5. ......

### MVCC是什么

多版本并发控制，实际上就是保存了数据在某个时间节点的快照。

我们每行数实际上隐藏了两列，创建时间版本号，过期(删除)时间版本号，每开始一个新的事务，版本号都会自动递增。

### 一条查询语句的执行流程

1. 检查该语句是否有权限，验证用户名和密码，获取权限列表
2. 检查该语句的语法，判断SQL语句的正确性
3. 优化器优化SQL语句，优化执行顺序
4. 进行权限校验，若有权限则调用数据库引擎接口，返回查询结果

### 一条更新语句的执行流程

比如

UPDATE t set k  = k+1 WHERE id = 5;

1. 执行器向引擎获取id=5的这条记录
2. 引擎从B+树中搜索这条记录，如果页在内存中，则直接从内存页中读取，若不在，需要先从磁盘中读出页，再从页中读出行返回
3. 执行器拿到这条记录之后，在此的记录上对k进行加1的操作，然后再写入这行数据
4. 引擎将此行更新到内存页中，并将此操作写入到redo log（在某某页上对某某行进行了什么操作），同时将其状态这是为prepare，告知执行器随时可以提交事务
5. 执行器将此操作写入到binlog
6. 执行器提交事务，引擎将redo log的状态置为commit，更新完成

### 为什么redo log和binlog 要分为3步

如果先写redo log， 再写bin log，此时如果mysql重启，redo log已经写入，mysql会从redolog恢复数据，但是binlog没有写入，同步数据到从库时会主从不一致

如果先写binlog，再写redo log，此时如果mysql重启，bin log已经写入，从库已经更新，而主库却丢失了更新。

### inoodb有哪几种日志

binlog： 保证服务器可以基于时间点恢复数据，主从复制

redo log：用于崩溃恢复的，保证mysql宕机也不会影响持久性

undo log：提供回滚，多个行版本控制

relay log：中继日志，存储所有主库TP过来的bin-log事件

### 为什么不对表中的每个列都创建索引

1. 对表中的数据增加、删除和修改的时候，索引页需要动态维护，会降低数据的维护速度
2. 索引需要占用物理空间
3. 创建索引和维护索引要耗费事件，这种时间随着数据量的增加会增加

### 聚集索引与非聚集索引

B+树节点只包含id索引列，而叶子节点包含索引列和数据，这种索引和数据在一起的叫做聚集索引，一张表只能有一个聚集索引

**非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。**

### 主键索引和二级索引

主键索引：

数据表的主键列使用的就是主键索引。一张数据表有只能有一个主键，并且主键不能为 null，不能重复。假设没有定义主键，InnoDB会选择一个唯一的非空索引代替，如果没有的话则会隐式定义一个主键作为聚簇索引。

二级索引：

辅助索引。通过二级索引，可以定位主键的位置。二级索引的叶子节点存储的数据是主键。唯一索引不是指只能有一个唯一索引，而是指唯一索引的属性列不允许存在重复的数据

### 什么是回表，覆盖索引有什么用

回表：通过普通索引定位主键值，再通过主键索引定位行记录

覆盖索引：只需要在一颗索引树上就能获取sql所需的所有字段的数据，无需回表。

如何实现索引覆盖：将被查询的字段，建立到联合索引里去。

### 联合索引和最左匹配原则

复合索引也叫组合索引，用户可以在多个列上建立索引,这种索引叫做复合索引(组合索引)。复合索引在数据库操作期间所需的开销更小,可以代替多个单一索引。

创建复合索引：CREATE INDEX columnId ON table1(col1,col2,col3) ;

使用复合索引：select * from table1 where col1= A and col2= B and col3 = C

另外，**联合索引具有最左匹配原则，即最左优先。** 比如，我们建立了一个2列的联合索引(col1,col2),实际上已经建立了两个联合索引(col1)、(col1,col2），解释如下。

联合索引的意义：

一个索引等于多个索引。比如建了一个(a,b,c)的复合索引，那么实际等于建了(a),(a,b),(a,b,c)三个索引，因为每多一个索引，都会增加写操作的开销和磁盘空间的开销。

作为覆盖索引。如果有如下的sql: select a,b,c from table where a=1 and b = 1。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。

索引列越多，通过索引筛选出的数据越少。

### Mysql索引创建的原则

1. 最适合的索引的列出现在where子列之中
2. 索引列的基数Cardinality越大，索引效果越好。高筛选性的列。什么是索引基数：例如，某个数据列包含值1、2、3、4、5、1，那么它的基数就是5。索引的基数相对于数据表行数较高（也就是说，列中包含很多不同的值，重复的值很少）的时候，它的工作效果最好。
3. 根据情况创建复合索引，复合索引可以提高查询效率。
4. 避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。
5. 主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。
6. 对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。

### 如何检查是否使用索引

用explain指令。 explain sql语句看结果是否是using index就知道是否使用了索引

### inner join left join right join

- INNER JOIN（内连接,或等值连接）：获取两个表中字段匹配关系的记录。
- LEFT JOIN（左连接）：获取左表所有记录，即使右表没有对应匹配的记录。
- RIGHT JOIN（右连接）： 与 LEFT JOIN 相反，用于获取右表所有记录，即使左表没有对应匹配的记录。

###  数据库会死锁吗，举一个死锁的例子，mysql是如何解决死锁的

例子：用户A访问表A（此时锁住了表A），而要去访问表B；用户B访问表B（锁住了表B），想要去访问表A。而此时用户A要获取表B内的数据需要先等待用户B释放该表，而用户B同样需要等待表A释放表A，因此产生了死锁。

如何解决：

1. 最简单的方式就是不要有等待，一发生等待事务就回滚。但是这会导致并发性能的下降，甚至任何一个事务都不能进行。
2. 设置一个等待时间阈值，如果超时，其中一个事务进行回滚，另一个事务就能继续进行
3. wait-for-graph的方式来进行死锁检测。innodb存储引擎页采用这种方式。wait-for-graph要求数据库保存两种信息，锁的信息链表和事务等待链表，若这两种链表构成的图中存在回路，就代表有死锁，innodb一般会选择回滚undo量最小的事务。

### mysql主从复制

1. 异步复制。mysql默认的复制。主库在执行完客户端提交的事务之后会立即将结果返回给客户端，并不关心从库是否已经接收到。性能最好，但是数据不一致问题出现的概率很大
2. 全同步复制。所有的从库都执行了该事务，主库才返回给客户端。性能较差。
3. 半同步复制。主库在等待至少一个从库接收到该事务并写到了relay log中才返回给客户端。

### 数据库三范式

1. 所有字段都是不可分解的原子值
2. 属性依赖于主键
3. 不存在传递依赖

### SQL注入攻击是什么，如何防范

SQL注入攻击，就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。

如何防范：

1. 在JDBC中，使用PreparedStatement来**拼接动态字符串**，可以保证输入的数据被视作SQL中纯粹的字符串
2. 对进入数据库的特殊字符进行转义处理或者编码转换
3. 网站每个数据库的编码统一
4. 严格限制网站用户对数据库的操作权限

### 自增主键可能的问题

Innodb自增值是通过其本身的自增长计数器来获取值的，叫做Auto INC locking。锁不是在每次事务完成之后释放，而是在完成对自增长值插入的SQL语句后释放，要等待其释放才能进行后序操作。如果有大量的并发插入，会引起sql阻塞。

另外，在多机数据库设计中，自增长主键ID会有重复现象，这也导致了系统设计时单点数据库不能拆库，因为ID会重复。

### 一条sql语句执行很慢的原因有哪些

1. redolog写满了，这个时候没办法等到空闲的时候再把数据同步到磁盘，只能先暂停其他操作，执行同步到磁盘的操作。

2. 内存不够用了：如果一次查询过多的数据，碰到的数据页也刚好不在内存中，需要申请内存，此时内存不足需要淘汰部分页面，如果是干净页直接释放，如果是脏页，就需要刷脏页

   当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。

3. 拿不到锁
4. 如果一直这么慢 检查sql语句的写法

## 操作系统

### **进程间的通信常见的的有哪几种方式呢?**

1. 管道
2. 有名管道
3. **信号量**：是一个计数器，用来控制多个进程对资源的访问，通常作为一种锁的机制
4. **信号**：用于通知接收进程某个事件已经发生
5. **消息队列**：是消息的链表
6. **套接字**：此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，
7. **共享内存**：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新

### 线程间的同步方式

1. 互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。synchronized和lock
2. 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. 事件：notify wait，通过通知操作的方式来保持多线程同步

### 进程的调度算法：

1. 先到先服务（FCFS）
2. **短作业优先（SJF）**
3. **最短剩余时间**
4. 时间片轮转
5. 多级反馈队列调度
6. **优先级调度**

### 页面置换算法的作用，常见的

当需要访问的页面不存在在内存中，会发生缺页中断，系统需要从磁盘中将其调入到主存中。而当发生缺页中断时，此时内存中没有空闲的页面，则会发生页面置换。

常见的页面置换算法：

1. 先进先出
2. 最近最久未使用LRU
3. 最少使用LFU
4. 最佳页面置换算法（OPT）

### 虚拟内存

通过虚拟内存，可以让程序拥有超过系统物理内存大小的可用内存空间。虚拟内存为每一个进程提供了一块私有的地址空间，让每个进程产生了一种自己独占内存的错觉（每个进程拥有一片连续完整的内存空间）。

作用：

1. 使用磁盘空间当作部分的虚拟地址空间的缓存
2. 为每个进程提供了统一的线性地址空间
3. 进程之间不会相互影响；用户程序不能访问内部信息和代码

### CPU寻址：

现代处理器使用的是虚拟寻址。虚拟寻址需要将虚拟地址翻译成物理地址，然后才能访问到真是的物理内存。需要CPU中的内存管理单元MMU实现。

如果虚拟地址在物理内存中，页命中，将虚拟地址翻译成物理地址

如果缺页，采用页面置换，再更新页表，再返回重来。

### 内核态和用户态

内核态：系统态，系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制

用户态：用户态运行的进程或可以直接读取用户程序的数据

### 用户态如何切换到内核态

1. 系统调度：用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作
2. 异常：当CPU在执行运行在用户态下的程序时，发生了异常，会由当前运行进程切换到处理异常的内核程序中
3. 中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

### fork()函数

在Linux系统中，创建子线程的方法是使用系统调用fork()函数。fork()函数用于从一个已存在的进程内创建一个新的进程，新的进程称为“子进程”，相应地称创建子进程的进程为“父进程”。使用fork()函数得到的子进程是父进程的复制品。区别有进程号、资源使用情况和计时器等。

区分父子进程常见的方法是查看fork()函数的返回值或者区分父子进程的PID。

### 银行家算法

避免死锁的算法。

1. 当资源池中剩余的可利用资源>=线程需要的资源时，可分配给内存
2. 线程可请求资源，但是请求的资源总数不能超过资源池中剩余的可利用资源
3. 当线程池中的资源暂时不满足当前的线程所需时，将此线程先暂时搁置，先将资源分配给能够满足需求的其他线程，等到满足搁置的线程之后，再分配
4. 线程拿到所需要的所有资源后，运行结束后，将自身的所有资源放回资源池中

### 操作系统的内存管理机制

1. 块式管理
2. 分段管理：将程序的空间划分为若干段，这样每个进程有一个二维地址空间，相互独立，互不干扰
3. 分页管理：将程序的逻辑地址划分为固定大小的页，不会产生外碎片，但会产生内碎片
4. 段页式管理：先把主存分为若干段，每个段又分为若干页，段与段之间以及段的内部都是离散的

### 快表与多级页表

在分页内存管理中，很重要的两点是：

1. 虚拟地址到物理地址的转换要快。
2. 解决虚拟地址空间大，页表也会很大的问题。

快表：可以把快表理解成一种特殊的缓存，其中的内容是页表的一部分或者全部内容。

使用快表的地址转换流程：

1. 根据虚拟地址中的页号查快表
2. 如果该页再快表中，直接从快表中获得该页的物理地址
3. 如果不在，就访问内存中的页表，再从内表中得到物理地址，同时添加到快表中
4. 当快表填满之后，又要登记新页时，就淘汰一个页



多级页表：

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景。



### 分页机制和分段机制有哪些共同点和区别呢？

共同点：

- 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

区别：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。

### 孤儿进程

父进程结束后，子进程还活着。

孤儿进程会被init进程收养，最后会回收

### 僵尸进程

一个子进程的**进程描述符**再子进程退出时不会释放，需要父进程操作来释放。而如果父进程未操作，那么子进程的进程描述符仍在系统中，称为僵尸进程。

危害：进程号是有限的，大量的僵尸进程会使得不能产生新进程

消灭僵尸进程 只需杀死父进程，此时僵尸进程变为孤儿进程，由init收集



## java基础

### java8大基本数据类型

1. byte
2. int
3. long
4. char
5. double
6. float
7. boolean
8. short

### equals和==

==只判断两个对象的地址是不是相等，基本数据类型比较值。

equals：如果类覆盖了equals，它会比较两个对象的内容是否相等，不能用于比较基本数据类型变量

### 重载与重写

重载：同一个方法名，不同的传参，执行不同的逻辑处理。如

重写：子类对父类的允许访问的方法进行实现过程。返回值类型、方法名和参数列表相同，抛出的异常小于等于父类的。如果父类方法用final static protected修饰，则子类不能重写该方法，不过被static修饰的方法可以再次被声明

### String，StringBuilder，StringBuffer

String类中使用final关键字来修饰字符数组，java 9 之后改用byte数组存储。每次对string改变之后，会生成一个新的String对象

StringBuffer是线程安全的，加了同步锁或者对方法加了同步锁

StringBuilder非线程安全

### 为什么重写equals必须重写hashcode

如果只重写equals方法，但不重写hashcode，两个仅内存地址不同但变量完全相同的对象会分别存入不同的桶。

### final关键字

用在 变量、方法、类中

1. 对于基本数据类型的变量，如果用final修饰后，一旦初始化之后就不能修改了，如果是引用类型的变量，则其不能再指向别的地址
2. 修饰类，表明这个类不能被继承。final类中的所有成员方法都会被隐式地指定未为final方法
3. 修饰方法，两种情况。第一种，锁定方法，以防任何继承类修改它的含义。第二种，效率，类中所有private方法都隐式地指定为final。

优点：

inal关键字提高了性能。JVM和Java应用都会缓存final变量。
2)final变量可以安全的在多线程环境下进行共享，而不需要额外的同步开销。
3)使用final关键字，JVM会对方法、变量及类进行优化。
4)不可变类创建不可变类要使用final关键字。不可变类是指它的对象一旦被创建了就不能被更改了。String是不可变类的代表。不可变类有很多好处，譬如它们的对象是只读的，可以在多线程环境下安全的共享，不用额外的同步开销等等。



### final修饰的对象，有几种初始化方式

修饰成员对象时有3种初始化方式：

- 在定义变量时直接赋值
- 声明完变量后在构造方法中为其赋值
- 声明完变量后在构造代码块中为其赋值

第二种：修饰类对象（静态对象）

- 在定义类变量时直接赋值
- 在静态代码块中赋值

### 异常

Throwable类有子类Exception（异常）和Error（错误）。Exception能被程序本身try-catch Error则无法处理

**受检查异常**

Java 代码在编译过程中，如果受检查异常没有被 `catch`/`throw` 处理的话，就没办法通过编译

**不受检查异常**

Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。

### 多态

实现多态的方式有两种方式，可以通过继承（多个⼦类对同⼀⽅法的重写）、也可以通过接⼝（实现接⼝并覆盖接⼝中同⼀⽅法）

方法重载是编译时多态，继承是运行时多态

### 接口和抽象类的区别

1. 接口的方法默认是 `public`，所有方法在接口中不能有实现(Java 8 开始接口方法可以有默认实现），而抽象类可以有非抽象的方法。
2. 接口中除了 `static`、`final` 变量，不能有其他变量，而抽象类中则不一定。
3. 一个类可以实现多个接口，但只能实现一个抽象类。接口自己本身可以通过 `extends` 关键字扩展多个接口。
4. 接口方法默认修饰符是 `public`，抽象方法可以有 `public`、`protected` 和 `default` 这些修饰符（抽象方法就是为了被重写所以不能使用 `private` 关键字修饰！）。
5. 从设计层面来说，抽象是对类的抽象，是一种模板设计，而接口是对行为的抽象，是一种行为的规范。

**抽象类的使用场景：**

 既想约束子类具有共同的行为（但不再乎其如何实现），又想拥有缺省的方法，又能拥有实例变量

**接口的应用场景：**

 约束多个实现类具有统一的行为，但是不在乎每个实现类如何具体实现；实现类需要具备很多不同的功能，但各个功能之间可能没有任何联系

### 多继承

Java不允许“实现多继承”，但支持“声明多继承”——就是Java的接口的多继承——一个**类**可以**实现**多个接口（“继承”了多个接口上的方法声明），而一个**接口**可以**继承**多个接口（同样是“继承”了多个接口上的方法声明）。

### 反射

是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法；并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能成为 Java 语言的反射机制。

JAVA语言编译之后会生成一个.class文件，反射就是通过字节码文件找到某一个类、类中的方法以及属性等。

###  反射可以访问private方法和属性吗？如何访问？

通过 setAccessible(true) 

### 反射原理

 反射首先是能够获取到Java中的反射类的**字节码**，然后将字节码中的方法，变量，构造函数等映射成相应的 Method、Filed、Constructor 等类

### Class.forName和ClassLoader区别

这两者，都可用来对类进行加载。差别在于：

- `Class#forName(...)` 方法，除了将类的 `.class` 文件加载到JVM 中之外，还会对类进行解释，执行类中的 `static` 块。
- ClassLoader 只干一件事情，就是将 `.class` 文件加载到 JVM 中，不会执行 `static` 中的内容，只有在 newInstance 才会去执行 `static` 块。

### int和Integer

Integer是int的封装类

Integer必须实例化之后才能用，int不需要

Integer实际是对象的引用，当new一个Integer时，实际上生成一个指针指向对象，而int则直接存储数值

Integer的默认值是null，而int的默认值是0。

### 装箱、拆箱

装箱：基本数据类型 ----> 对应包装类类型，这个过程叫装箱。
拆箱：包装类类型 ----> 对应基本数据类型，这个过程叫拆箱。

自动装箱和拆箱从Java 1.5开始引入，目的是将原始类型值转自动地转换成对应的对象。自动装箱与拆箱的机制可以让我们在Java的变量赋值或者是方法调用等情况下使用原始类型或者对象类型更加简单直接。

### 深拷贝 潜拷贝

潜拷贝：对于基本数据类型进行值传递，引用数据类型进行引用传递

深拷贝：对于基本数据类型进行值传递，引用数据类型，创建一个新的对象，拷贝其内容。

### 基本类型和引用类型

基本类型存储在栈中，直接存储值的对应字节数据

而引用类型存储在堆中，栈中存储的只是指向堆中对象的地址

### 静态代理和动态代理

静态代理模式的代理类，只是实现了特定类的代理，代理类对象的方法越多，你就得写越多的重复的代码。动态代理就可以动态的生成代理类，实现对不同类下的不同方法的代理。

### 动态代理

**jdk动态代理步骤**：

1. 编写需要被代理的类和接口
2. 编写代理类，实现InvocationHandler接口，重写invoke()方法
3. 使用`Proxy.newProxyInstance(ClassLoader loader, Class<?>[] interfaces, InvocationHandler h)`动态创建代理类对象，通过代理类对象调用业务方法。

**如果想代理没有实现接口的对象，CGLIB**

CGLIB 框架是基于继承实现的，所以可以对无接口的对象进行代理。它会对目标类产生一个代理子类，拦截父类的方法调用。代理子类需要实现 `MethodInterceptor` 接口。



### 静态内部类和非静态内部类

非静态内部类编译后会默认的保存一个指向外部类的引用，而静态类却没有，所以其不能使用外部类的非static成员变量和成员方法。

### finalize()的作用，既然有垃圾回收的机制，为什么要有这个

`finalize()`函数通常用于释放 Java 调用 C/C++ 方法产生的对象的内存

### public protected default private

- public 都可以访问

- protected 同包内的类 以及 不同包的子类 可以访问       即使在别的包中创建子类，均能够访问来自**任意包的**父类的被protected修饰的属性或方法。

- default 只能在 同包 的类中调用

- private 只能自己访问

  **private < default < protected < public**

### java内部类

成员内部类、局部内部类、匿名内部类、静态内部类

+ 成员内部类可以无条件访问外部类的所有成员属性和成员方法（包括private成员和静态成员）。在外部类中如果要访问成员内部类的成员，必须先创建一个成员内部类的对象，再通过指向这个对象的引用来访问。
+ 局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。注意，局部内部类就像是方法里面的一个局部变量一样，是不能有public、protected、private以及static修饰符的。
+ 匿名内部类是唯一一种没有构造器的类。匿名内部类因为是匿名，所以不能显式地声明构造函数，也不能往构造函数里传参数。
+ 静态内部类是不需要依赖于外部类的，这点和类的静态成员属性有点类似，并且它不能使用外部类的非static成员变量或者方法。

### 各种类可用的修饰符

外部类：public default abstract final

内部类：public protected default private abstract final static

局部内部类：abstract final

### 泛型的类型擦除 能否被重载

Java的泛型是伪泛型，这是因为Java在编译期间，所有的泛型信息都会被擦掉。ava的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参数，在编译器编译的时候会去掉，这个过程成为类型擦除。

泛型 不能 重载

+ 在编译期间会对使用泛型的进行类型检查，
+ 但是编译时会把泛型擦除，去掉泛型都是list，不能重载
+ 有界泛型使用 super extends 框定 可以使用&

### 创建字符串有两种方式：两种内存区域（pool heap）

+ ""方式创建的字符串在字符串常量池中。 
+ new 创建字符串时，首先查看字符串常量池中是否有相同的字符串，如果有则拷贝一份放到堆中，然后返回堆中的地址；如果池中没有则在池中先创建，然后还会去堆中再创建一份字符串的对象，然后把常量池中的字符串内容拷贝至堆中对象，然后返回堆内存中字符串对象的内存地址。

### Arrays.sort()底层

对于大数组（长度大于286），会采用归并，因为快排要用到递归，数组规模太大可能会栈溢出，而归并非递归

如果长度小于47，会用插入排序

如果长度大于47，基本数据类型用快排，引用类型用归并（为了稳定性）

### 什么是序列化 反序列化失败的场景：

序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。

- 可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。
- 序列化是为了解决在对对象流进行读写操作时所引发的问题。

**反序列化失败的场景：**

 序列化ID：serialVersionUID不一致的时候，导致反序列化失败



### transient关键字

1）一旦变量被transient修饰，变量将不再是对象持久化的一部分，该变量内容在序列化后无法获得访问。

2）transient关键字只能修饰变量，而不能修饰方法和类。注意，本地变量是不能被transient关键字修饰的。变量如果是用户自定义类变量，则该类需要实现Serializable接口。

3）被transient关键字修饰的变量不再能被序列化，一个静态变量不管是否被transient修饰，均不能被序列化

## java集合类

### HashMap、HashTable、ConcurrentHashMap

HashMap： JDK1.8 之前 `HashMap` 由数组+链表组成的，采用拉链法。JDK1.8 后，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

插入原理：

判断数组是否为空，为空进行初始化;
不为空，计算 k 的 hash 值，通过 (n - 1) & hash计算应当存放在数组中的下标 index ;
查看 table[index] 是否存在数据，没有数据就构造一个Node节点存放在 table[index] 中；
存在数据，说明发生了hash冲突, 继续判断key是否相等，相等，用新的value替换原数据(onlyIfAbsent为false)；
如果不相等，判断当前节点类型是不是树型节点，如果是树型节点，创建树型节点插入红黑树中；
如果不是树型节点，创建普通Node加入链表中；判断链表长度是否大于 8， 大于的话链表转换为红黑树；
插入完成之后判断当前节点数是否大于阈值，如果大于开始扩容为原数组的二倍。

HashTable:线程安全的过时类

ConcurrentHashMap：

1.7版本的ConcurrentHashMap采用分段锁机制(也就是每一个 Segment 上同时只有一个线程可以操作)，里面包含一个Segment数组，Segment则包含HashEntry的数组，每个HashEntry是一个HashMap，而默认的Segment长度是16，也就是支持16个线程的并发写，Segment之间相互不会受到影响。

**1.8CAS+synchronized**,  **Node 数组 + 链表 / 红黑树**

1.8抛弃分段锁，转为用CAS+synchronized来实现。主要还是看put的流程。

1. 根据 key 计算出 hashcode 。
2. 判断是否需要进行初始化。
3. 即为当前 key 定位出的 Node，如果为空表示当前位置可以写入数据，利用 CAS 尝试写入，失败则自旋保证成功。
4. 如果当前位置的 `hashcode == MOVED == -1`,则需要进行扩容。
5. 如果都不满足，则利用 synchronized 锁写入数据。
6. 如果数量大于 `TREEIFY_THRESHOLD` 则要转换为红黑树。

### 为什么引入红黑树

红黑树就是为了解决二叉查找树在某些情况下会退化成线性结构的问题。

### HashMap多线程操作导致死循环问题

主要原因在于 并发下的Rehash 会造成元素之间会形成一个循环链表。不过，jdk 1.8 后（头插变尾插）解决了这个问题，但是还是不建议在多线程下使用 HashMap,因为多线程下使用 HashMap 还是会存在其他问题比如数据丢失。并发环境下推荐使用 ConcurrentHashMap 。

### 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同

`HashSet` 无序，底层是HashMap(散列表+红黑树)，非线程同步。

`LinkedHashSet` 迭代有序，底层是HashMap+双向链表，非线程同步；

`TreeSet` 有序，底层是TreeMap(红黑树)，而TreeMap的key也就是TreeSet的元素不允许为null，非线程同步。

如何使用map实现：key是元素，value是同一个Object

### HashMap种hash(Object key)的原理

tab[(n-1) & hash]，其中n是数组的长度

1 为什么这里没有使用模运算呢，因为对于现代处理器来说，除法和求余数（模运算）是最慢的操作。

2 当b是2的指数时，等式 a % b = (b-1) & a  成立，所以可以使用tab[(n-1) & hash]代替取模运算tab[hash % n] 计算数组下标。

##### HashMap 的容量为什么建议是 2的幂次方？

因为2^n-1的二进制所有位上全为1，这样能最大限度的利用hash值，更好的散列，减少hash碰撞。只要&的数二进制某位上有0，对应的1就肯定不会出现（因为&只有都是1才会为1），这样会限制散列的范围。

比如16的二进制是10000，15是01111，16&任何数都只能是0或16，15&任何数可以取到小于16的任何数。

##### 为什么 h = key.hashCode()) 与 (h >>> 16) 异或

当length=2的N次方， 下标运算结果只取决于哈希值的低N位，而绝大多数情况下length一般都小于2^16即小于65536，始终是hashcode 的低16位（甚至更低）参与 h & (length-1) 运算。要是高16位也参与运算，会让得到的下标更加散列。所以我们将(h >>> 16)得到他的高16位与hashCode()进行^运算。

### HashMap在几的时候会转成[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)，几的时候又转回来，为什么这么设置？

若桶中[链表]()元素个数大于等于8时，[链表]()转换成树结构；若桶中[链表]()元素个数小于等于6时，树结构还原成[链表]()。

   + **因为[红黑树]()的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用[链表]()，平均查找长度为8/2=4，这才有转换为树的必要。**
   + **选择6和8，中间有个差值7可以有效防止[链表]()和树频繁转换。**假设一下，如果设计成[链表]()个数超过8则[链表]()转换成树结构，[链表]()个数小于8则树结构转换成[链表]()，如果一个HashMap不停的插入、删除元素，[链表]()个数在8左右徘徊，就会频繁的发生树转[链表]()、[链表]()转树，效率会很低。
   + 在随机哈希代码下，桶中的节点频率遵循泊松分布，文中给出了桶长度k的频率表。由频率表可以看出，**桶的长度超过8的概率非常非常小。**所以可能根据概率统计而选择了8作为阀值。



### **Set**里的元素是不能重复的，那么用什么方法来区分重复与否呢**?** 是用**==**还是**equals()?**

添加元素的时候，如果key(也对应的Set集合的元素)相等，那么则修改value值。而在Set集合中，value 值仅仅是一个Object对象罢了(该对象对**Set**本身而言是无用的)。

也就是说:Set集合如果添加的元素相同时，是根本没有插入的**(**仅修改了一个无用的**value**值**)**!从源码 (HashMap)中也看出来，**==**和**equals()**方法都有使用!



### Hashmap遍历方法

这三个迭代器，分别对应 `entrySet`，`keySet` 和 `values` 方法返回对象的迭代器。这三个方法分别返回 `EntrySet` ，`KeySet` 和 `Values` 对象，这三个类均定义在 `HashMap` 中。

   ```java
   Iterator iter = map.entrySet().iterator();
   while (iter.hasNext()) {
       Map.Entry entry = (Map.Entry) iter.next();
       Object key = entry.getKey();
       Object val = entry.getValue();
   }
   ```

### Arraylist Linkedlist 操作的时间复杂度

   + ArrayList 是线性表（数组）
     get()   										  o(1)
     add(E) 尾部添加，				  	o(1)
     add(index, E) 							  o(n)
     remove()						              o(n)

   + linkedlist 双链表

     get() 											 o(n)
     add(E) 										  o(1)
     add(index, E) 				 先查找o(n),再添加o(1)
     remove()								      o(1)

   + HashSet                                        o(1)

   + TreeSet                                       o(logn)

### hashmap 在迭代遍历的时候进行remove操作会发生什么

如果对正在被迭代的集合进行结构上的改变（即对该集合使用add、remove或clear方法），那么迭代器就不再合法（并且在其后使用该迭代器将会有ConcurrentModificationException异常被抛出）。

如果使用迭代器自己的remove方法，那么这个迭代器就仍然是合法的。

### **Collection**和**Collections**的区别

Collection是集合的上级接口，继承它的有Set和List接口

Collections是集合的工具类，提供了一系列的静态方法对集合的搜索、查找、同步等操作

### CopyOnWriteArrayList

   + CopyOnWriteArrayList底层由数组实现，volatile修饰
   + 在修改时，复制出一个新数组，修改的操作在新数组中完成，最后将新数组交由**array**变量指向。 
   + 写加锁，读不加锁，使用ReentrantLock的lock()和unlock()
   + 迭代器得到的是原数组，所以遍历时获取到的是旧数据

缺点：

   + 内存占用:如果CopyOnWriteArrayList经常要增删改里面的数据，经常要执行 add()、set()、 remove() 的话，那是比较耗费内存的。因为我们知道每次 add()、set()、remove() 这些增删改操作都要复制一个数组出来。
   + 数据一致性:CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。

### 多线程环境下如何使用Map

多线程环境可以使用Map m = Collections.synchronizedMap(new HashMap());同步加锁的方式，还可以使用HashTable，但是同步的方式显然性能不达标，而ConurrentHashMap更适合高并发场景使用。

## Java多线程

### 进程和线程

进程：是程序运行的过程，是**资源分配的最小单位**，进程中包含多个线程，多个线程在共享进程中的堆、方法区

线程：**cpu任务调度的最小执行单位**，每个线程拥有自己的程序计数器、虚拟机栈、本地方法栈

### 什么是上下文切换

当一个任务的时间片用完之后，会切换到另一个任务。在切出时，操作系统会保存当前任务的状态。在切入时，操作系统会从内存中加载任务的状态。

### 线程的生命周期和状态

NEW：创建新的线程

RUNNABLE：包括就绪态和运行态、

BLCOKED：阻塞状态，因为锁的竞争

WAITING：使用sleep和wait方法进入等待状态的线程，需要依靠其他线程的通知才能够返回

TIME_WAITING：可以在指定时间内返回

TEMINATED：终止状态

### sleep和wait区别

sleep会释放锁，而wait不会

sleep一般用来暂停执行线程，而wait用来进程线程之间的交流

wait方法被调用后线程需要别的线程调用同一个对象上的notify/notifyall，而sleep执行完之后会自动苏醒

### 死锁，如何避免

四个必要条件：

1. 互斥条件：一个资源只能被一个线程占用
2. 保持与等待条件：一个线程在等待获取另一个资源的时候，不会释放自己占有的资源
3. 不可剥夺条件：线程已经获得的资源在其未用完之前 不会被其他线程强行占有
4. 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源

如何避免:

1. 破坏保持与等待条件：一次性申请所有的资源
2. 破坏不可剥夺条件：如果申请不到，那么就释放自己的资源
3. 破坏循环等待条件：按顺序申请资源，反序释放资源

### JMM：

Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。

JMM 是一种规范，是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重[排序]()、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。

原子性：在 Java 中可以使用 Synchronized 来保证方法和代码块内的操作是原子性的

可见性：Java 中的 Volatile 关键字修饰的变量在被修改后可以立即同步到主内存。被其修饰的变量在每次使用之前都从主内存刷新。因此，可以使用 Volatile 来保证多线程操作时变量的可见性。除了 Volatile，Java 中的 Synchronized 和 Final 两个关键字也可以实现可见性。只不过实现方式不同

有序性：在 Java 中，可以使用 Synchronized 和 Volatile 来保证多线程之间操作的有序性。区别：Volatile 禁止指令重排。Synchronized 保证同一时刻只允许一条线程操作。     



所有的变量都存储在主内存中，每个线程还有自己的工作内存，工作内存存储在高速缓存或者寄存器中，保存了该线程使用的变量的主内存副本拷贝。

处理器上的寄存器的读写的速度比内存快几个数量级，为了解决这种速度矛盾，在它们之间加入了高速缓存。加入高速缓存带来了一个新的问题：缓存一致性。

### volatile作用？底层实现？

作用：

1. “可见性”，被volatile修饰的变量能够使得每个线程都能获取到该值的最新值
2. 防止指令重排：在多线程条件下，指令重排可能会导致计算结果不一致

底层实现：

加入volatile关键字时，会多出一个lock前缀指令”lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：

1. 它确保指令重[排序]()时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
2. **它会强制将对缓存的修改操作立即写入主存；**
3. **如果是写操作，它会导致其他CPU中对应的缓存行无效。**

### CAS

需要读写内存值V，进行比较的值A，准备写入的值B，当且仅当V的值等于A的值的时候，才用B的值去更新V的值，否则不操作，进行自旋。

### CAS缺点

**ABA问题**：解决方法引入版本号

**循环时间开销大**：自旋长时间不成功，会给CPU带来很大的开销

**只能保证一个共享变量的原子操作**

### synchronized底层实现

对象头中主要由Mark Word和Class Metadata Address，其中Mark Word存储对象的hashcode，锁信息 分代年龄 gc标志等等，class metadata address是类型指针指向对象的类元数据。

锁可分为四个状态：无锁，偏向锁、轻量级锁、重量级锁。锁的类型和状态都在对象头中记录。

每个锁都有一个对应的monitor对象，当一个monitor被某个线程持有后，它便处于锁定状态。

### 如何使用synchronized

- `synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁。
- `synchronized` 关键字加到实例方法上是给对象实例上锁。
- 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能！

### 实现单例

```java
public class Singlton{
    private volatile static Singlton uniqueInstance;
    
    private Singlton(){}
    
    public static Singlton getUniqueInstance(){
        if(uniqueInstance == null){
            synchronized(Singleton.class){
                if(if uniqueInstance == null){
                    uniqueInstance = new Singlton();
                }
            }
        }
        return uniqueInstance;
    }
}
```

### ReentrantLock是什么？底层实现？

reentrantlock是lock接口的其中一个实现类，需要使用lock()和unlock()配合try/finally来完成

底层实现：ReentrantLock的实现是一种自旋锁，通过循环调用CAS操作来实现加锁。它的性能比较好也是因为避免了使线程进入内核态的阻塞状态。

### ReentrantLock和ReentrantReadWriteLock

+ ReentrantReadWriteLock和ReentrantLock都支持公平和非公平模式
+ ReentrantReadWriteLock是一个读写锁。它使用的state变量高**16**位是读锁，低**16**位是写锁
+ 写锁可以降级为读锁，读锁不能升级为写锁
+ 写锁是互斥的，读锁是共享的

### 非公平锁原理

非公平锁：一个线程申请该资源的时候，如果申请失败就会到队列的末尾。

公平锁：申请失败仍在队列首部，继续申请

### ReentrantLock和synchronized比较

synchronized会自动释放锁，是java的内置关键字，lock是一个接口，必须手动释放，否则会发生死锁

synchronized是不可中断的，而且不知道自己是否获得了锁，lock可中断，且可知

两者都是默认非公平锁，但是lock可实现公平锁

synchronized是悲观锁，reentrantlock是乐观锁



### java对象头

1. Mark Word
2. 指向类的指针
3. 数组长度(只有数组对象才有)

### java锁升级

无锁->偏向锁->轻量级锁->重量级锁

1. 检查当前的对象的对象头内是否是自己的线程ID，如果是，表示当前线程处于偏向锁状态
2. 如果不是，锁升级，用CAS来执行切换，新的线程根据现有的ThreadID，通知之前线程暂停，将Markword置为空
3. 两个线程把锁对象的hashcode复制到自己的用于存储锁的记录空间，开始CAS，把锁对象的markword内容修改为自己新建的记录空间的地址的方式竞争markword
4. 如果成功，则获得资源，失败则进入自旋
5. 自旋过程中 获得资源，整个状态依然是轻量级锁的状态
6. 若失败，进入重量级锁的状态，这个时候，自旋的进程阻塞，等待之前的线程执行完成唤醒自己

### AQS

AQS是实现锁的框架

**AQS 核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。**

AQS为实现阻塞锁和相关同步器提供了一个框架，它是依赖于**先进先出的等待队列**；

**依靠单个原子int值来表示状态，**该状态用于表示锁是获取中还是释放，通过指定的方法改变状态的值。

**使用volatile修饰int型变量state实现线程可见性，修改state状态值时使用CAS算法。**

### 可重入锁

synchronized中叫做偏向锁

lock中叫做可重入锁，即**允许同一个线程多次获取同一把锁**，比如一个递归函数里有加锁操作，递归过程中这个锁会阻塞自己吗？如果不会，那么这个锁就是**可重入锁**

### TreadLocal

ThreadLocal提供了线程的局部变量，每个线程可以通过set get来对这个局部变量进行操作，实现了线程的数据隔离

### ThreadLocal底层

1. 每一个Thread维护着一个ThreadLocalMap的引用
2. threadlocalmap是threadlocal的内部类，用entry来进行存储
3. set方法就是往threadlocalmap里设置值，key是指向threadlocal对象的弱引用
4. get就是从threadLocalMap里获取值
5. ThreadLocal本身不存储值，只是让key来让线程获取value

什么时候赋值：一般会重写initialValue()方法来赋值，在每个线程第一次访问get的时候会调用initialValue()方法。

为什么不使用HashMap：1）可以限定key为ThreadLocal对象。 2）HashMap的key是强引用

为什么设置为弱引用

如果使用强引用，当原来key原来对象失效的时候，jvm不会回收map里面的ThreadLocal

### ThreadLocal内存泄漏

ThreadLocalMap中的key为ThreadLocal是弱引用，弱引用在下一次GC时必然会被清理掉（如果没有被外部强引用的情况下）。

key被清理了，但是value是强引用，还在，这样一来出现key为null的value，不采取任何措施value永远不会被GC回收。

ThreadLocalMap实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。如果说会出现内存泄漏，那只有在出现了 key 为 null 的记录后，没有手动调用 remove() 方法，并且之后也不再调用 get()、set()、remove() 方法的情况下。



### 为什么要用线程池

1. 降低资源消耗，每次线程的创建和销毁都需要消耗资源
2. 加快响应速度，无需等待线程的建立
3. 提高线程的可管理性。线程是稀缺资源，无限制创建会消耗系统资源，还会降低系统稳定性

### 线程池的参数和执行流程

首先线程池有几个核心的参数概念：

1. 最大线程数maximumPoolSize
2. 核心线程数corePoolSize
3. 活跃时间keepAliveTime
4. 活跃时间的时间单位TimeUnit
5. 阻塞队列workQueue
6. 线程工厂threadFactory
7. 拒绝策略RejectedExecutionHandler

当提交一个新任务到线程池时，具体的执行流程如下：

1. 当我们提交任务，线程池会根据corePoolSize大小创建若干任务数量线程执行任务
2. 当任务的数量超过corePoolSize数量，后续的任务将会进入阻塞队列阻塞排队
3. 当阻塞队列也满了之后，将会新值线程数至maximumPoolSize，如果任务处理完成，这额外创建的线程在等待keepAliveTime后会被自动销毁
4. 如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理

### 线程池的拒绝策略

1. AbortPolicy：直接丢弃任务，抛出异常
2. CallerRunsPolicy：调用execute函数的上层线程执行被拒绝的任务
3. DiscardOldesPolicy：丢弃最旧的
4. DiscardPolicy：丢弃 不抛异常

### Executors类可以创建哪些线程池

1. newSingleThread**Executor** 创建**一个单线程化**的线程池，只有一个线程的线程池，因此所有提交的任务是顺序执行，适用于一个一个任务执行的场景
2. newFixedThreadPool 拥有**固定线程数**的线程池，可控制线程最大并发数，超出的线程会在队列中等待。
3. newScheduledThreadPool 创建一个**可定期或者延时执行**任务的定长线程池，支持定时及周期性任务执行。 
4. newCachedThreadPool 线程池里有**很多线程需要同时执行**，老的可用线程将被新的任务触发重新执行，如果线程超过60秒内没执行，那么将被终止并从池中删除，适用执行很多短期异步的小程序或者负载较轻的服务

### 为什么阿里不让用Executors类的几种线程池

FixedThreadPool 和 SingleThreadExecutor ： 允许请求的**队列⻓度**为 Integer.MAX_VALUE，可能堆积⼤量的请求，从⽽导致OOM(out fo memory)。
CachedThreadPool 和 ScheduledThreadPool ： 允许创建的**线程数量**为 Integer.MAX_VALUE，可能会创建⼤量线程，从⽽导致OOM。

### 线程池的大小如何设置

**CPU 密集型**

- CPU 密集的意思是该任务需要大量的运算，而没有阻塞，CPU 一直全速运行。 
- CPU 密集型任务尽可能的少的线程数量，一般为 **CPU 核数 + 1 个**线程的线程池。 

**IO 密集型**

- 由于 IO 密集型任务线程并不是一直在执行任务，可以多分配一点线程数，如 **CPU * 2** 
- 也可以使用公式：CPU 核数 / (1 - 阻塞系数)；其中阻塞系数在 0.8 ～ 0.9 之间。

### CountDownLatch(闭锁)、CyclicBarrier(栅栏)、Semaphore(信号量) 

Java为我们提供了三个同步工具类:

CountDownLatch(闭锁) 某个线程等待其他线程执行完毕后，它才执行(其他线程等待某个线程执行完毕后，它才执行)

CyclicBarrier(栅栏) 一组线程互相等待至某个状态，这组线程再同时执行。

Semaphore(信号量) 控制一组线程同时执行

###  ReenTrantLock中的condition有什么作用？condition的await和signal和Object的wait和notify有什么区别？

**Condition的强大之处在于，对于一个锁，我们可以为多个线程间建立不同的Condition**。

如果采用Object类中的wait(), notify(), notifyAll()实现的话，当写入数据之后需要唤醒读线程时，不可能通过notify()或notifyAll()明确的指定唤醒读线程，而只能通过notifyAll唤醒所有线程，但是notifyAll无法区分唤醒的线程是读线程，还是写线程。所以，通过Condition能够更加精细的控制多线程的休眠与唤醒。

### 什么是阻塞队列？阻塞队列的实现原理是什么？如何使用阻塞队列来实现生产者-消费者模型？

阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。

这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。

阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。

### join()和yield()

`join()`方法表示无限等待，它会一直阻塞当前线程，直到目标线程执行完毕

`yield()`方法表示当前线程让出CPU，重新进行CPU资源的竞争



## JVM

### JVM运行时内存划分

堆：用来存放实例对象/数组，GC主要区域

方法区/元空间：用来存放静态变量，常量，类信息

线程：线程内部有程序计数器、本地方法栈、虚拟机栈

程序计数器：如果有线程之间的切换的话，程序计数器会记录当前运行到的位置，等下次切换回来之后继续在原来的位置往下运行

虚拟机栈：有局部变量表、**动态链接**、**操作数栈**、**返回地址**

局部变量表：用来存放方法的参数、方法内部定义的局部变量。

动态链接：符号引用一部分在解析时转换成直接引用，称为静态解析，而在运行时转换成直接引用，称为动态链接

操作数栈：操作数栈可理解为java虚拟机栈中的一个用于计算的临时数据存储区。

返回地址：指向了一条字节码指令的地址

本地方法栈：服务于本地native方法

### 引用类型

强引用：new一个 不会被GC回收

软引用：如果内存不满不会GC回收，如果内存快满了 会对这对引用进行回收

弱引用：下次GC必定回收

虚引用：几乎等于无引用，用来跟踪对象被垃圾回收的过程

### 堆内存分配策略

1. 对象优先分配在eden区，如果eden区满了，会进行一次minor gc，存活的对象进入s1区
2. 大对象直接进入Old区，避免大对象过多地拷贝
3. 如果在s区的对象的年龄大于一定阈值之后，该对象会进入old区
4. 动态判断，如果某个年龄的对象的总数大于总空间的一般，则大于等于这个年龄的对象全部进入老年代。

### Full GC触发条件

1. System.gc() 不一定区执行，只是建议
2. 老年代空间不足
3. 空间分配担保失败：何为空间担保：因为eden区容纳不下接下来对象B所需内存的大小，虚拟机将发起一次 Minor GC，GC期间虚拟机又发现之前的对象A无法存入 Survivor 空间，所以只好通过分配担保机制把新生代的对象A提前转移到老年代中去，老年代有足够的内存存放。
4. 永久代空间不足 1.7之前
5. Concurrent Mode Failure：CMS GC过程中有对象进入老年代，老年代不足 会触发

### 为什么要设置survivor

减少Full GC的发生次数，full gc消耗的时间比minor gc花费的时间多得多，设置survivor可减少被送到老年代的对象

### 为什么设置两个survivor

主要是给了让内存连续，如果只有一个s区，进行一次minor gc的话 eden区和s区都有部分存活对象，而这是吧eden区的对象放到s区的话，内存是不连续的，因此设置一个s2区，把存活对象全部复制过去，内存才能联系

### 如何判断对象是否存活

1. 引用计数法：新增引用增加1，失去引用减少1，但是无法解决对象间相互引用的问题
2. GC ROOT 可达性分析：从GC root为根节点，从这些根节点往下搜索，搜索所走过的路径称为引用链，当一个对象不与任何引用链相连时，则证明这个对象不可用

未标记的对象未必非死不可，如果当对象没有覆盖 finalize 方法，或 finalize 方法已经被虚拟机调用过时，虚拟机将这两种情况视为没有必要执行。

### 有哪些GC ROOTS

1. 虚拟机栈中的 栈帧引用对象
2. 本地方法栈中JNI中栈帧引用的对象
3. 方法区中常量引用的对象
4. 方法区类中的静态变量引用的对象
5. 所有被同步锁持有的对象

### 垃圾回收算法

复制算法：内存缩小，利用率低，复制操作，效率低

标志清除算法：产生大量不连续的内存

标志整理算法：

分代收集算法

### 垃圾收集器

Serial，Parnew，parallel Scavenge，Serialold，Parnewold，CMS, G1

Serial：单线程的收集器，阻塞

Parnew：多线程版本

parallel Scavenge：高吞吐量

SerialOld：老年代的Serial

parallel old：老年代的parallel Scavenge

#### CMS：

主要是为了获取最短的停顿时间，分为四个阶段：

1. 初始标记，只标记与GCroot之间关联的对象，会暂停其他线程
2. 并发标记，进行GCROOT跟踪过程，不会暂停
3. 重新标记，修正因为用户运行而产生变动的那些标记，会暂停
4. 并发清除，清除GCROOT不可达对象，不需要暂停

优点：并发收集、低停顿

缺点：对CPU资源敏感；⽆法处理浮动垃圾；使⽤“标记清除”算法导致⼤量空间碎⽚产⽣。

remark过程标记活着的对象，从GCRoot的可达性判断对象活着，但无法标记“死亡”的对象。
如果在初始标记阶段被标记为活着，并发运行过程中“死亡”，remark过程无法纠正，因此变为浮动垃圾，需等待下次gc的到来。

#### G1(garbage first)

相对于CMS：使用标记整理算法，不产生内存碎片，可以非常精确控制停顿时间，在不牺牲吞吐量前提下，实现低停顿垃圾回收。

G1把堆内存划分为多个区域，跟踪这些区域内的垃圾收集进度，在后台维护一个优先级的列表，每次根据所允许的收集时间，优先回收垃圾最多的区域。

### 类加载过程

1. 加载：把字节码转换成二进制流的过程
2. 验证：校验CLass文件是否符合jvm虚拟机的规范
3. 准备：为静态变量、常量（被 static 修饰的变量）赋默认值
4. 解析：把常量池中的符号引用替换为直接引用
5. 初始化：执行static代码进行初始化

### new一个对象的过程

1. 为对象分配内存
2. 接着为实例变量赋默认值
3. 分配对象头信息
4. 初始化，执行构造函数

### 双亲委派机制

当我们在加载类的时候，首先都会向上询问父加载器是否已经加载，如果没有则依次向上询问，如果没有加载，则从上到下依次尝试是否能加载当前类，直到加载成功。

**好处：**此机制保证JDK核心类的优先加载；使得Java程序的稳定运⾏，可以避免类的重复加载，也保证了 Java 的核⼼ API 不被篡改。如果不⽤没有使⽤双亲委派模型，⽽是每个类加载器加载⾃⼰的话就会出现⼀些问题，⽐如我们编写⼀个称为 java.lang.Object 类的话，那么程序运⾏的时候，系统就会出现多个不同的Object 类。

## Spring

### Spring的一些重要模块

- **Spring Core：** 基础,可以说 Spring 其他所有的功能都需要依赖于该类库。主要提供 IoC 依赖注入功能。
- **Spring Aspects** ： 该模块为与AspectJ的集成提供支持。
- **Spring AOP** ：提供了面向切面的编程实现。
- **Spring JDBC** : Java数据库连接。
- **Spring JMS** ：Java消息服务。
- **Spring ORM** : 用于支持Hibernate等ORM工具。
- **Spring Web** : 为创建Web应用程序提供支持。
- **Spring Test** : 提供了对 JUnit 和 TestNG 测试的支持。

### @RestController vs @Controller

单独的@Controller一般使用在需要返回一个视图的情况

@RestController返回JSON或XML形式数据

@RestController = @Controller + @ResponseBody

### Spring IOC

IoC（Inverse of Control:控制反转）是一种**设计思想**，就是 **将原本在程序中手动创建对象的控制权，交由Spring框架来管理。** **IoC 容器实际上就是个Map（key，value）,Map 中存放的是各种对象。** **IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件/注解即可，完全不用考虑对象是如何被创建出来的。**

### AOP

AOP是能够让我们在不影响原有功能的前提下，为软件**横向扩展**功能

我们在WEB项目开发中，通常都遵守三层原则，包括控制层（Controller）->业务层（Service）->数据层（dao）,那么从这个结构下来的为纵向，它具体的某一层就是我们所说的横向

当我们需要为多个对象引入一个公共行为，比如日志，操作记录等，就需要在每个对象中引用公共行为，这样程序就产生了大量的重复代码，使用AOP可以完美解决这个问题。

**Spring AOP就是基于动态代理的**，如果要代理的对象，实现了某个接口，那么Spring AOP会使用**JDK Proxy**，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候Spring AOP会使用 **Cglib** 生成一个被代理对象的子类来作为代理。

静态代理：创建一个接口，然后创建被代理的类实现该接口并且实现该接口中的抽象方法。之后再创建一个代理类，同时使其也实现这个接口。在代理类中持有一个被代理对象的引用，而后在代理类方法中调用该对象的方法。

动态代理：通过实现 InvocationHandler 接口创建自己的调用处理器；

通过为 Proxy 类指定 ClassLoader 对象和一组 interface 来创建动态代理类；

通过反射机制获得动态代理类的构造函数，其唯一参数类型是调用处理器接口类型；

通过构造函数创建动态代理类实例，构造时调用处理器对象作为参数被传入。

### @Component @Bean

1. 作用对象不同: `@Component` 注解作用于类，而`@Bean`注解作用于方法。
2. `@Component`通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 `@ComponentScan` 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。`@Bean` 注解通常是我们在标有该注解的方法中定义产生这个 bean,`@Bean`告诉了Spring这是某个类的示例，当我需要用它的时候还给我。
3. `@Bean` 注解比 `Component` 注解的自定义性更强，而且很多地方我们只能通过 `@Bean` 注解来注册bean。比如当我们引用第三方库中的类需要装配到 `Spring`容器时，则只能通过 `@Bean`来实现。

### 用过的注解

#### @SpringBootApplication

我们可以把 `@SpringBootApplication`看作是 `@Configuration`、`@EnableAutoConfiguration`、`@ComponentScan` 注解的集合。

- `@EnableAutoConfiguration`：启用 SpringBoot 的自动配置机制
- `@ComponentScan`： 扫描被`@Component` (`@Service`,`@Controller`)注解的 bean，注解默认会扫描该类所在的包下所有的类。
- `@Configuration`：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类

#### @Autowired

自动导入对象到类中，被注入进的类同样要被 Spring 容器管理比如：Service 类注入到 Controller 类中，Mapper类注入到Service中

#### @Component

通用的注解，可标注任意类为 `Spring` 组件

#### @Service

对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao /Mapper层

#### @Controller

对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面

#### @RestController

#### @RequestBody

用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且**Content-Type 为 application/json** 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。

#### @Param

对应xml文件中的字段名

#### @RequestMapping

RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上

### SPRING  MVC

MVC 是一种设计模式

Spring MVC 下我们一般把后端项目分为 Service层（处理业务）、Dao层（数据库操作）、Entity层（实体类）、Controller层(控制层，返回数据给前台页面)。

#### 工作原理：

1. 客户端（浏览器）发送请求，直接请求到 `DispatcherServlet`。
2. `DispatcherServlet` 根据请求信息调用 `HandlerMapping`，解析请求对应的 `Handler`。
3. 解析到对应的 `Handler`（也就是我们平常说的 `Controller` 控制器）后，开始由 `HandlerAdapter` 适配器处理。
4. `HandlerAdapter` 会根据 `Handler `来调用真正的处理器来处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 `ModelAndView` 对象，`Model` 是返回的数据对象，`View` 是个逻辑上的 `View`。
6. `ViewResolver` 会根据逻辑 `View` 查找实际的 `View`。
7. `DispaterServlet` 把返回的 `Model` 传给 `View`（视图渲染）。
8. 把 `View` 返回给请求者（浏览器）

### 用到的设计模式

- **工厂设计模式** : Spring使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象。
- **代理设计模式** : Spring AOP 功能的实现。
- **单例设计模式** : Spring 中的 Bean 默认都是单例的。
- **模板方法模式** : Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。
- **包装器设计模式** : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。
- **观察者模式:** Spring 事件驱动模型就是观察者模式很经典的一个应用。
- **适配器模式** :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配`Controller`。

## MyBatis

### #{}和${}的区别

Mybatis在处理${}时，就是把${}直接替换成变量的值。而Mybatis在处理#{}时，会对sql语句进行预处理，将sql中的#{}替换为?号，调用PreparedStatement的set方法来赋值；

使用#{}可以有效的防止SQL注入，提高系统安全性。

### 常见标签

```xml
<!--生成对应的map-->
<mapper>
    <!--生成对应的实体类-->
    <resultMap>
        <!--主键-->
        <id></id>
        <!--其他字段-->
        <result></result>
    </resultMap>
    <!--所有字段名-->
    <sql>
    </sql>
    <!--插入-->
    <insert>
    </insert>
    <!--选择-->
    <select>
    </select>
</mapper>
```

### Dao接口的工作原理？参数不同时，能重载吗？

Dao 接口，就是人们常说的 `Mapper`接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名

Dao 接口的工作原理是 JDK 动态代理，MyBatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行`MappedStatement`所代表的 sql，然后将 sql 执行结果返回。

**Mybatis 的 Dao 接口可以有多个重载方法，但是多个接口对应的映射必须只有一个，否则启动会报错。**

### Mybatis如何进行分页？分页插件的原理是什么？

MyBatis 使用 RowBounds 对象进行分页，它是针对 ResultSet 结果集执行的内存分页，而非物理分页，可以在 sql 内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。

分页插件的基本原理是使用 MyBatis 提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写 sql，根据 dialect 方言，添加对应的物理分页语句和物理分页参数

### 为什么说MyBatis是半自动ORM（对象关系映射）映射工具？它与全自动的区别在哪里？

Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 MyBatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。

## Netty

### 什么是Netty

1. Netty 是一个 **基于 NIO** 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。
2. 它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。
3. **支持多种协议** 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。

**Netty 成功地找到了一种在不妥协可维护性和性能的情况下实现易于开发，性能，稳定性和灵活性的方法。**

使用Netty的开源项目：Dubbo、RocketMQ、Elasticsearch、gRPC。

### 为什么使用Netty

统一的 API，支持多种传输类型，阻塞和非阻塞的。

简单而强大的线程模型。

自带编解码器解决 TCP 粘包/拆包问题。

自带各种协议栈。

真正的无连接数据包套接字支持。

比直接使用 Java 核心 API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制。

安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。

社区活跃

成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。

### Netty应用场景

1. **作为 RPC 框架的网络通信工具** ：我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。
2. **实现一个自己的 HTTP 服务器** ：
3. **实现一个即时通讯系统** ：使用 Netty 我们可以实现一个可以聊天类似微信的即时通讯系统
4. **实现消息推送系统** ：市面上有很多消息推送系统都是基于 Netty 来做的。

### 为什么Netty性能高

IO 线程模型：同步非阻塞，用最少的资源做更多的事。 

内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。 

内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。 

串行化处理读写：避免使用锁带来的性能开销。 

高性能序列化协议：支持 protobuf 等高性能序列化协议。 

### 零拷贝

在 OS 层面上的 `Zero-copy` 通常指避免在 `用户态(User-space)` 与 `内核态(Kernel-space)` 之间来回拷贝数据。

在netty中：

1. 使用 Netty 提供的 CompositeByteBuf 类, 可以将多个ByteBuf 合并为一个逻辑上的 ByteBuf, 避免了各个 ByteBuf 之间的拷贝。
2. ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf, 避免了内存的拷贝。
3. 通过 FileRegion 包装的FileChannel.tranferTo 实现文件传输, 可以直接将文件缓冲区的数据发送到目标 Channel, 避免了传统通过循环 write 方式导致的内存拷贝问题.

### Netty核心组件、作用

+ Channel：`Channel` 接口是 Netty 对网络操作抽象类，它除了包括基本的 I/O 操作，如 `bind()`、`connect()`、`read()`、`write()` 等。两个实现类NioServerSocketChannel和NioSocketChannel
+ EventLoop：`Channel` 为 Netty 网络操作(读写等操作)抽象类，`EventLoop` 负责处理注册到其上的`Channel` 处理 I/O 操作，两者配合参与 I/O 操作。
+ ChannelHandler 和 ChannelPipeline：`ChannelHandler` 是消息的具体处理器。他负责处理读写操作、客户端连接等事情。ChannelPipeline 为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。
+ ChannelFuture：Netty 所有的 I/O 操作都为异步的，因此我们需要 ChannelFuture 的 addListener()注册一个 ChannelFutureListener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。另外，我们还可以通过 `ChannelFuture` 接口的 `sync()`方法让异步的操作变成同步的。

### EventloopGroup 及和eventloop关系

`EventLoopGroup` 包含多个 `EventLoop`（每一个 `EventLoop` 通常内部包含一个线程），当客户端通过 `connect` 方法连接服务端时，`bossGroup` 处理客户端连接请求。当客户端处理完成后，会将这个连接提交给 `workerGroup` 来处理，然后 `workerGroup` 负责处理其 IO 相关操作。

### Bootstrap 和 ServerBootstrap

1. `Bootstrap` 通常使用 `connet()` 方法连接到远程的主机和端口，作为一个 Netty TCP 协议通信中的客户端。另外，`Bootstrap` 也可以通过 `bind()` 方法绑定本地的一个端口，作为 UDP 协议通信中的一端。
2. `ServerBootstrap`通常使用 `bind()` 方法绑定本地的端口上，然后等待客户端的连接。
3. `Bootstrap` 只需要配置一个线程组— `EventLoopGroup` ,而 `ServerBootstrap`需要配置两个线程组— `EventLoopGroup` ，一个用于接收连接，一个用于具体的处理。

### Netty长连接 心跳机制了解吗

长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 **心跳机制** 。

心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle 状态时, 客户端或服务器就会发送一个特殊的数据包给对方, 当接收方收到这个数据报文后, 也立即发送一个特殊的数据报文, 回应发送方, 此即一个 PING-PONG 交互。所以, 当某一端收到心跳消息后, 就知道了对方仍然在线, 这就确保 TCP 连接的有效性.

### Netty的线程模型

Netty通过 Reactor 模型基于多路复用器接收并处理用户请求，内部实现了两个线程池， boss 线程池和 worker 线程池，其中 boss 线程池的线程负责处理请求的 accept 事件，当接收到 accept 事件的请求时，把对应的 socket 封装到一个 NioSocketChannel 中，并交给 worker 线程池，其中 worker 线程池负责请求的 read 和 write 事件， 由对应的Handler 处理。

单线程模型：这个模式reactor和handler在一个线程中，如果某个handler阻塞的话，会导致其他所有的handler无法执行，而且无法充分利用多核的性能。

多线程模型：有一个NIO 线程（Acceptor） 只负责监听服务端，接收客户端的TCP 连接请求；NIO 线程池负责网络IO 的操作，即消息的读取、解码、编码和发送；1 个NIO 线程可以同时处理N 条链路，但是1 个链路只对应1 个NIO 线程，这是为了防止发生并发操作问题。但在并发百万客户端连接或需要安全认证时，一个Acceptor 线程可能会存在性能不足问题。

主从多线程模型：Acceptor 线程用于绑定监听端口，接收客户端连接，将SocketChannel 从主线程池的 Reactor 线程的多路复用器上移除，重新注册到Sub 线程池的线程上，用于处理I/O 的读写等操作，从而保证 mainReactor 只负责接入认证、握手等操作；

## Redis

### 什么是redis

NOSQL，redis的数据是存在内存中的，读写速度很快，广泛用于缓存方向。Redis还用来做分布式锁，消息队列。提供多种数据类型来支持不同的业务场景，支持事务，持久化，Lua脚本，多种集群方案。

### 分布式缓存常见的技术选型方案有哪些

比较多的是Memcached和redis，不过基本使用redis

### Redis和Mencached的区别和共同点

共同点：

1. NOSQL，一般当作缓存使用
2. 都有过期策略
3. 性能都高

区别：

1. Redis支持更多的数据类型，k/v list set zset hash等 而memcached只支持k/v
2. redis支持数据的持久化，可以将内存中的数据保存到磁盘中，而memecache全部保存在内存中
3. redis有灾难恢复机制，因为有数据持久化
4. redis在使用完服务器内存之后会保存到磁盘上，而memecached会报错
5. m没有原生的集群模式，需要依靠客户端来实现往集群分片中写入数据，但是redis是支持cluster模式的
6. m是多线程的，非阻塞IO复用的网络模型，R支持单线的多路IO复用
7. Redis支持发布订阅模型、Lua脚本、事务等，redis支持更多的编程语言，而m不行
8. m过期数据的删除策略只用了惰性删除，r同时使用了惰性删除与定期删除

### 缓存数据的处理流程是怎样的？

1. 如果用户请求的数据在缓存中就直接返回。
2. 缓存中不存在的话就看数据库中是否存在。
3. 数据库中存在的话就更新缓存中的数据。
4. 数据库中不存在的话就返回空数据。

### 为什么要用Redis 为什么用缓存

高性能：保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了

高并发：一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。

> QPS（Query Per Second）：服务器每秒可以执行的查询次数；

### 常见数据结构

#### string

简单的 key-value 类型。

一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

#### list

链表。Redis 的 list 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

发布与订阅或者说消息队列、慢查询。

#### hash

hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。

系统中对象数据的存储。

### set

 set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。

需要存放的数据不能重复以及需要获取多个数据源交集和并集等场景

#### sorted set

和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。

#### bitmap

bitmap 存储的是连续的二进制数字（0 和 1），通过 bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 bitmap 本身会极大的节省储存空间。

适合需要保存状态信息（比如是否签到、是否登录...）并需要进一步对这些信息进行分析的场景。比如用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。

### Redis单线程模型详解

**Redis 基于 Reactor 模式来设计开发了自己的一套高效的事件处理模型**

**既然是单线程，那怎么监听大量的客户端连接呢？**

Redis 通过**IO 多路复用程序** 来监听来自客户端的大量连接（或者说是监听多个 socket），它会将感兴趣的事件及类型(读、写）注册到内核中并监听每个事件是否发生。

### 6.0之后为什么引入了多线程

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

### Redis给缓存数据设置过期时间的作用

一般情况下，我们设置保存的缓存数据的时候都会设置一个过期时间。为什么呢？

因为内存是有限的，如果缓存中的所有数据都是一直保存的话，分分钟直接 Out of memory。

Redis 自带了给缓存数据设置过期时间的功能

**过期时间除了有助于缓解内存的消耗，还有什么其他用么？**

很多时候，我们的业务场景就是需要某个数据只在某一时间段内存在，比如我们的短信验证码可能只在 1 分钟内有效，用户登录的 token 可能只在 1 天内有效。

### Redis是如何判断数据是否过期的呢

Redis 通过一个叫做**过期字典**（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key(键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间

### 过期数据的删除策略了解吗

常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

1. **惰性删除** ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。
2. **定期删除** ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

所以 Redis 采用的是 **定期删除+惰性/懒汉式删除** 。

### Redis内存淘汰机制了解吗

但是，仅仅通过给 key 设置过期时间还是有问题的。因为还是可能存在定期删除和惰性删除漏掉了很多过期 key 的情况。这样就导致大量过期 key 堆积在内存里，然后就 Out of memory 了。

怎么解决这个问题呢？答案就是： **Redis 内存淘汰机制。**

Redis 提供 6 种数据淘汰策略：

1. **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2. **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3. **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4. **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5. **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6. **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1. **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2. **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

### Redis持久化机制

**Redis 的一种持久化方式叫快照（snapshotting，RDB），另一种方式是只追加文件（append-only file, AOF）**

**快照（snapshotting）持久化（RDB）**

Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。

快照持久化是 Redis 默认采用的持久化方式

**AOF（append-only file）持久化**

与快照持久化相比，AOF 持久化 的实时性更好，因此已成为主流的持久化方案。

开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入硬盘中的 AOF 文件。

### Redis事务

**Redis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。**

**Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断。**



### 缓存穿透

缓存穿透说简单点就是大量请求的 key 根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。

![缓存穿透情况](https://snailclimb.gitee.io/javaguide/docs/database/Redis/images/redis-all/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E6%83%85%E5%86%B5.png)

#### 如何处理

最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。

1. 缓存无效key

   如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。

2. 布隆过滤器

   布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个“人”。

   具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

   加入布隆过滤器之后的缓存处理流程图如下。

   ![image](https://snailclimb.gitee.io/javaguide/docs/database/Redis/images/redis-all/%E5%8A%A0%E5%85%A5%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%90%8E%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B.png)

但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： **布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。**

我们先来看一下，**当一个元素加入布隆过滤器中的时候，会进行哪些操作：**

1. 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
2. 根据得到的哈希值，在位数组中把对应下标的值置为 1。

我们再来看一下，**当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：**

1. 对给定元素再次进行相同的哈希计算；
2. 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。

然后，一定会出现这样一种情况：**不同的字符串可能哈希出来的位置相同。** （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）

### 缓存雪崩

**缓存在同一时间大面积的失效，后面的请求都直接落到了数据库上，造成数据库短时间内承受大量请求。**

举个例子：系统的缓存模块出了问题比如宕机导致不可用。造成系统的所有访问，都要走数据库。

还有一种缓存雪崩的场景是：**有一些被大量访问数据（热点缓存）在某一时刻大面积失效，导致对应的请求直接落到了数据库上。**

#### 解决方法

**针对 Redis 服务不可用的情况：**

1. 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。
2. 限流，避免同时处理大量的请求。

**针对热点缓存失效的情况：**

1. 设置不同的失效时间比如随机设置缓存的失效时间。
2. 缓存永不失效。

### 如何保证缓存和数据库数据的一致性

1. **缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。
2. **增加 cache 更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。



